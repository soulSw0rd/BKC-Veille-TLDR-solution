# TLDR Tech Scraper

Un scraper Python pour extraire et analyser les rapports quotidiens de [TLDR Tech](https://tldr.tech).

## Description

Ce projet permet de rÃ©cupÃ©rer automatiquement les articles du rapport quotidien TLDR Tech pour n'importe quelle date. Il extrait les titres, contenus, URLs et catÃ©gories des articles, avec des options de filtrage et d'export.

## FonctionnalitÃ©s

- ğŸ—ï¸ Scraping des rapports quotidiens TLDR Tech
- ğŸ“… Support de dates personnalisÃ©es (format YYYY-MM-DD)
- ğŸ·ï¸ Extraction des catÃ©gories d'articles
- ğŸ’° DÃ©tection des articles sponsorisÃ©s
- ğŸ” Filtrage par catÃ©gorie
- ğŸš« Exclusion des articles sponsorisÃ©s
- ğŸ“„ Export au format JSON
- ğŸ”‡ Mode silencieux
- ğŸ“Š Statistiques (nombre d'articles trouvÃ©s)

## Installation

1. Clonez le repository :
```bash
git clone <repository-url>
cd BKC-Veille-TLDR-solution
```

2. Installez les dÃ©pendances :
```bash
pip install -r requirements.txt
```

## Utilisation

### Utilisation basique

Scraper le rapport du jour :
```bash
python tldr_scrapper.py
```

### Options avancÃ©es

```bash
# Scraper une date spÃ©cifique
python tldr_scrapper.py --date 2024-12-20

# Exporter au format JSON
python tldr_scrapper.py --json

# Exporter avec un nom de fichier personnalisÃ©
python tldr_scrapper.py --json --output mon_rapport.json

# Mode silencieux (pas d'affichage des articles)
python tldr_scrapper.py --silent

# Filtrer par catÃ©gorie
python tldr_scrapper.py --category "BIG TECH & STARTUPS"

# Exclure les articles sponsorisÃ©s
python tldr_scrapper.py --no-sponsor

# Combinaison d'options
python tldr_scrapper.py --date 2024-12-20 --json --no-sponsor --category "SCIENCE & FUTURISTIC TECHNOLOGY"
```

### Utilisation comme module Python

```python
from tldr_scrapper import scrape_tldr_tech, export_to_json

# Scraper le rapport du jour
result = scrape_tldr_tech()

# Scraper une date spÃ©cifique
result = scrape_tldr_tech("2024-12-20")

# VÃ©rifier le succÃ¨s
if result["status"] == "success":
    print(f"TrouvÃ© {result['article_count']} articles")
    
    # AccÃ©der aux articles
    for article in result["articles"]:
        print(f"- {article['title']}")
        print(f"  CatÃ©gorie: {article['category']}")
        print(f"  URL: {article['url']}")
        print(f"  Contenu: {article['content'][:100]}...")
        print()
    
    # Exporter en JSON
    export_to_json(result, "rapport.json")
else:
    print(f"Erreur: {result['message']}")
```

## Structure des donnÃ©es

Le scraper retourne un dictionnaire avec la structure suivante :

```python
{
    "status": "success",
    "title": "TLDR",
    "subtitle": "Tech",
    "date": "2024-12-20",
    "url": "https://tldr.tech/tech/2024-12-20",
    "article_count": 15,
    "articles": [
        {
            "title": "Titre de l'article",
            "url": "https://example.com/article",
            "content": "Contenu de l'article...",
            "category": "BIG TECH & STARTUPS",
            "is_sponsored": false
        },
        // ... autres articles
    ]
}
```

## CatÃ©gories typiques

Les articles sont gÃ©nÃ©ralement classÃ©s dans ces catÃ©gories :
- **BIG TECH & STARTUPS** - ActualitÃ©s des grandes entreprises tech et startups
- **SCIENCE & FUTURISTIC TECHNOLOGY** - Innovations et technologies d'avenir
- **PROGRAMMING, DESIGN & DATA SCIENCE** - DÃ©veloppement, design et data science
- **MISCELLANEOUS** - Divers

## Gestion des erreurs

Le scraper gÃ¨re automatiquement plusieurs types d'erreurs :

- **404/307** : Rapport non disponible pour la date demandÃ©e
- **Format de date invalide** : Message d'erreur explicite
- **Erreurs rÃ©seau** : Gestion des timeouts et erreurs de connexion
- **Parsing HTML** : Validation de la structure des donnÃ©es

## Options de ligne de commande

| Option | Description | Exemple |
|--------|-------------|---------|
| `--date` | Date au format YYYY-MM-DD | `--date 2024-12-20` |
| `--json` | Exporter au format JSON | `--json` |
| `--output` | Nom du fichier de sortie JSON | `--output rapport.json` |
| `--silent` | Mode silencieux | `--silent` |
| `--category` | Filtrer par catÃ©gorie | `--category "BIG TECH"` |
| `--no-sponsor` | Exclure les articles sponsorisÃ©s | `--no-sponsor` |

## Exemples d'utilisation

### Analyse quotidienne automatisÃ©e
```bash
# Script pour analyser le rapport du jour et l'archiver
python tldr_scrapper.py --json --no-sponsor --output "archives/tldr_$(date +%Y-%m-%d).json"
```

### Recherche par catÃ©gorie
```bash
# Extraire uniquement les articles de science et technologie
python tldr_scrapper.py --category "SCIENCE" --no-sponsor
```

### Export pour analyse
```bash
# Exporter en mode silencieux pour traitement automatique
python tldr_scrapper.py --date 2024-12-20 --json --silent --output data.json
```

## DÃ©pendances

- **requests** (>=2.31.0) : RequÃªtes HTTP
- **beautifulsoup4** (>=4.12.0) : Parsing HTML
- **lxml** (>=4.9.0) : Parser XML/HTML rapide

## Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## Avertissements

- Respectez les conditions d'utilisation de TLDR Tech
- N'abusez pas du scraping (limitez la frÃ©quence des requÃªtes)
- Ce scraper est Ã  des fins Ã©ducatives et de veille technologique

## Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Signaler des bugs
- Proposer des amÃ©liorations
- Soumettre des pull requests

## Support

Si vous rencontrez des problÃ¨mes :
1. VÃ©rifiez que toutes les dÃ©pendances sont installÃ©es
2. VÃ©rifiez votre connexion internet
3. Assurez-vous que la date est au bon format (YYYY-MM-DD)
4. Consultez les messages d'erreur pour plus de dÃ©tails
